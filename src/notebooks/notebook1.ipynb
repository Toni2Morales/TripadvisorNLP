{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tonim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tonim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from pycaret.classification import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/New_Delhi_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_review</th>\n",
       "      <th>review_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Totally in love with the Auro of the place, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I went this bar 8 days regularly with my husba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We were few friends and was a birthday celebra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fatjar Cafe and Market is the perfect place fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hey Guys, if you are craving for pizza and sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147576</th>\n",
       "      <td>5</td>\n",
       "      <td>Near by airport very calm and cool environment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147577</th>\n",
       "      <td>5</td>\n",
       "      <td>My favourite place to stay. Great service. Ash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147578</th>\n",
       "      <td>5</td>\n",
       "      <td>good food with nice decoration, drinks list al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147579</th>\n",
       "      <td>4</td>\n",
       "      <td>Near to airport .it is fine property.  Staff i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147580</th>\n",
       "      <td>5</td>\n",
       "      <td>Amazing food ..  Excellent ambience ..  Great ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147581 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating_review                                        review_full\n",
       "0                   5  Totally in love with the Auro of the place, re...\n",
       "1                   5  I went this bar 8 days regularly with my husba...\n",
       "2                   5  We were few friends and was a birthday celebra...\n",
       "3                   5  Fatjar Cafe and Market is the perfect place fo...\n",
       "4                   5  Hey Guys, if you are craving for pizza and sea...\n",
       "...               ...                                                ...\n",
       "147576              5  Near by airport very calm and cool environment...\n",
       "147577              5  My favourite place to stay. Great service. Ash...\n",
       "147578              5  good food with nice decoration, drinks list al...\n",
       "147579              4  Near to airport .it is fine property.  Staff i...\n",
       "147580              5  Amazing food ..  Excellent ambience ..  Great ...\n",
       "\n",
       "[147581 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División entre train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(data[\"review_full\"], data[\"rating_review\"], test_size = 0.2, shuffle = True, random_state = 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain.str.replace(r\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|()|()\",\"\", regex = True)\n",
    "xtest = xtest.str.replace(r\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|()|()\",\"\", regex = True)\n",
    "xtrain = xtrain.str.replace(r\"()|(\\-)|(\\/)\",\"\", regex = True)\n",
    "xtest = xtest.str.replace(r\"()|(\\-)|(\\/)\",\"\", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain2 = []\n",
    "for x in xtrain:\n",
    "    xtrain2.append(str(x).split())\n",
    "xtest2 = []\n",
    "for x in xtest:\n",
    "    xtest2.append(str(x).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = []\n",
    "xtest = []\n",
    "def lemmatize_func(data, new_data):\n",
    "    for num, row in enumerate(data):\n",
    "        new_data.append([])\n",
    "        for word in row:\n",
    "            new_data[num].append(lemmatizer.lemmatize(word))\n",
    "lemmatize_func(xtrain2, xtrain)\n",
    "lemmatize_func(xtest2, xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"I've\", 'been', 'to', 'this', 'place', 'last', 'year', 'a', 'well', 'and', 'this', 'place', 'ha', 'not', 'lost', 'it', 'touch', 'since', 'then', 'Quality', 'of', 'the', 'food', 'is', 'perfect', 'great', 'service', 'and', 'wide', 'variety', 'of', 'food', 'Ambience', 'is', 'also', 'perfect', 'and', 'the', 'restaurant', 'ha', 'it', 'own', 'valet', 'parking', 'which', 'give', 'it', 'a', 'plus', 'point'], ['Went', 'for', 'party', 'The', 'service', 'wa', 'really', 'disappointing', 'Food', 'wa', 'ok', 'ok', 'Must', 'improve', 'their', 'hospitality']]\n",
      "[[\"It's\", 'really', 'one', 'of', 'my', 'favourite', 'place', 'for', 'eating', 'South', 'Indian', 'food', 'because', 'taste', 'is', 'really', 'awesome', 'and', 'so', 'great'], ['I', 'have', 'eaten', 'here', 'many', 'time', 'and', 'taken', 'group', 'here', 'The', 'food', 'is', 'always', 'good', 'and', 'the', 'service', 'quick', 'and', 'efficient', 'My', 'group', 'have', 'always', 'loved', 'the', 'food', 'and', 'they', 'always', 'get', 'the', 'order', 'right', 'and', 'do', 'separate', 'billing', 'which', 'is', 'great', 'for', 'group']]\n"
     ]
    }
   ],
   "source": [
    "print(xtrain[:2])\n",
    "print(xtest[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "def join_func(data, new_data):\n",
    "    for row in data:\n",
    "        new_data.append(\" \".join(row))\n",
    "join_func(xtrain, X_train)\n",
    "join_func(xtest, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '00 00', '00 00pm', ..., 'ｂｙtheir recommendations',\n",
       "       'ｎーｂｌｏｃｋで買い物に疲れたら寄ってみるとよい', 'ｎーｂｌｏｃｋで買い物に疲れたら寄ってみるとよい cafe'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stopwords.words(\"english\"), ngram_range=(1,2))\n",
    "vectorizer.fit(data[\"review_full\"].values.astype(str))\n",
    "xtrain = vectorizer.transform(X_train)\n",
    "xtest = vectorizer.transform(X_test)\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5785818341972423"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest, rf.predict(xtest))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos a probar con otro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(data[\"review_full\"], data[\"rating_review\"], test_size = 0.2, shuffle = True, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain.str.replace(r\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|()|()\",\"\", regex = True)\n",
    "xtest = xtest.str.replace(r\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|()|()\",\"\", regex = True)\n",
    "xtrain = xtrain.str.replace(r\"()|(\\-)|(\\/)\",\"\", regex = True)\n",
    "xtest = xtest.str.replace(r\"()|(\\-)|(\\/)\",\"\", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain2 = []\n",
    "for x in xtrain:\n",
    "    xtrain2.append(str(x).split())\n",
    "xtest2 = []\n",
    "for x in xtest:\n",
    "    xtest2.append(str(x).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = []\n",
    "xtest = []\n",
    "def stemmer_func(data, new_data):\n",
    "    for num, row in enumerate(data):\n",
    "        new_data.append([])\n",
    "        for word in row:\n",
    "            new_data[num].append(stemmer.stem(word))\n",
    "stemmer_func(xtrain2, xtrain)\n",
    "stemmer_func(xtest2, xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "def join_func(data, new_data):\n",
    "    for row in data:\n",
    "        new_data.append(\" \".join(row))\n",
    "join_func(xtrain, X_train)\n",
    "join_func(xtest, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '00 00', '00 00pm', ..., 'ｂｙtheir recommendations',\n",
       "       'ｎーｂｌｏｃｋで買い物に疲れたら寄ってみるとよい', 'ｎーｂｌｏｃｋで買い物に疲れたら寄ってみるとよい cafe'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stopwords.words(\"english\"), ngram_range=(1,2))\n",
    "vectorizer.fit(data[\"review_full\"].values.astype(str))\n",
    "xtrain = vectorizer.transform(X_train)\n",
    "xtest = vectorizer.transform(X_test)\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5572720804959853"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest, rf.predict(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5640478368397872"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest, rf.predict(xtest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
